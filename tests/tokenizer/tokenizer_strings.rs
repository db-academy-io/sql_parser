// THIS IS AN AUTOGENERATED TESTS, DO NOT MODIFY!
//
// The cargo dbcheck will generate the test files for each stage of the course.
// Be careful; these files are not intended to be edited by students. You're
// free to add more tests in separate files, but don't delete or edit tests
// generated by the testing tool

/* --------------- TESTS CREATED FROM TOKENIZER SPECIFICATION ---------------
 *             (see https://www.sqlite.org/draft/tokenreq.html)
 */
#![allow(non_snake_case)]

use super::{run_rainy_day_test, run_sunny_day_test};
use sql_parser::{TokenType, TokenizerError};

/// H41200: SQLite shall recognize as a STRING token a sequence of characters
/// that begins with a single-quote (u0027), is followed by zero or more
/// non-zero characters and/or pairs of single-quotes (u0027) and terminates
/// with a single-quote (u0027) that is not part of a pair.
#[test]
fn test_H41200() {
    let valid_test_cases = vec![
        ("''", vec![TokenType::String("''"), TokenType::Semi]),
        (
            "'Hello, world!'",
            vec![TokenType::String("'Hello, world!'"), TokenType::Semi],
        ),
        (
            "'It''s a nice day'",
            vec![TokenType::String("'It''s a nice day'"), TokenType::Semi],
        ),
        (
            "'He said, ''Hello!'' and left.'",
            vec![
                TokenType::String("'He said, ''Hello!'' and left.'"),
                TokenType::Semi,
            ],
        ),
        (
            "'''starting with quote'",
            vec![
                TokenType::String("'''starting with quote'"),
                TokenType::Semi,
            ],
        ),
        (
            "'ending with quote'''",
            vec![TokenType::String("'ending with quote'''"), TokenType::Semi],
        ),
        (
            "'multiple ''''quotes'",
            vec![TokenType::String("'multiple ''''quotes'"), TokenType::Semi],
        ),
        (
            "'123''456''789'",
            vec![TokenType::String("'123''456''789'"), TokenType::Semi],
        ),
    ];

    for (sql, expected_tokens) in valid_test_cases {
        run_sunny_day_test(sql, expected_tokens);
    }
}

#[test]
fn test_H41200_rainy_day_cases() {
    let invalid_test_cases = vec![
        // Missing closing quote
        (
            "'Missing closing quote",
            TokenizerError::UnterminatedLiteral("'Missing closing quote"),
        ),
        // Last quote is part of a pair, missing final quote
        (
            "'Ends with pair''",
            TokenizerError::UnterminatedLiteral("'Ends with pair''"),
        ),
    ];

    for (sql, expected) in invalid_test_cases {
        run_rainy_day_test(sql, vec![], expected);
    }
}
